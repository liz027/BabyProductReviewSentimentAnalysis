{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04e82eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# for basic visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# for advanced visualizations\n",
    "import plotly.offline as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "init_notebook_mode(connected = True)\n",
    "import plotly.figure_factory as ff\n",
    "import pyrsm as rsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44983074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183531, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/amazon_baby.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703cf504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "341f6b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "      <td>neutual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating sentiment  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3   neutual  \n",
       "1  it came early and was not disappointed. i love...       5  positive  \n",
       "2  Very soft and comfortable and warmer than it l...       5  positive  \n",
       "3  This is a product well worth the purchase.  I ...       5  positive  \n",
       "4  All of my kids have cried non-stop when I trie...       5  positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify the rating to different sentiment level. \n",
    "df['sentiment']=rsm.ifelse(df.rating>=4,'positive',rsm.ifelse(df.rating==3,'neutual','negative'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "233711bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name         318\n",
       "review       829\n",
       "rating         0\n",
       "sentiment      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f97b9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name         0\n",
       "review       0\n",
       "rating       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with Null value\n",
    "df=df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e33aae0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182384, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efbdc47",
   "metadata": {},
   "source": [
    "### Build Word2Vec and Glove model\n",
    "\n",
    "Use 100 dimension to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb8eb904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwords') \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c71a8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "ps = PorterStemmer() \n",
    "\n",
    "def pre_processing_by_nltk(doc, stemming = True, need_sent = False):\n",
    "    # step 1: get sentences\n",
    "    sentences = sent_tokenize(doc)\n",
    "    # step 2: get tokens\n",
    "    tokens = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent)\n",
    "#         step 3 (optional): stemming\n",
    "        if stemming:\n",
    "            words = [ps.stem(word) for word in words]\n",
    "        if need_sent:\n",
    "            tokens.append(words)\n",
    "        else:\n",
    "            tokens += words\n",
    "    return [w.lower() for w in tokens if w.lower() not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df291a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset for later use.\n",
    "# Stemming dataset\n",
    "sentences=df.review.apply(pre_processing_by_nltk).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9495209e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['sentiment'].values\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d03c3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "model = Word2Vec(vector_size=100, min_count=2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba598122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-a01a00e813f3>:6: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build Glove model.\n",
    "\n",
    "glove_file = 'glove.6B.100d.txt'\n",
    "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "model_glove = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfcbad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences, y, test_size = 0.2,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a37041c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32709\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(X_train)\n",
    "model.train(X_train, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "print(len(model.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67927778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define definition to get average vectoers.\n",
    "import numpy as np\n",
    "\n",
    "# For Word2Vec model\n",
    "def get_mean_vector(doc, wv):\n",
    "    vecs = []\n",
    "    for token in doc:\n",
    "        try:\n",
    "            vecs.append(wv.wv[token])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return np.mean(vecs, axis=0)\n",
    "\n",
    "# For GloVe model\n",
    "def get_mean_vector1(doc, wv):\n",
    "    vecs = []\n",
    "    for token in doc:\n",
    "        try:\n",
    "            vecs.append(wv[token])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return np.mean(vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5eeaf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "embedding_weights = pickle.load(open('data/embedding_weights.pkl', 'rb'))\n",
    "avg=embedding_weights.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c5ec50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights_test = pickle.load(open('data/embedding_weights_test.pkl', 'rb'))\n",
    "avg_test=embedding_weights_test.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdf248f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d18a0448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:188: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average train vector for stemming model.\n",
    "import numpy\n",
    "all_vectors_train = []\n",
    "for i in range(0,len(X_train)):\n",
    "    vec = get_mean_vector(X_train[i],model)\n",
    "    if numpy.isnan(vec).all():\n",
    "        all_vectors_train.append(avg)\n",
    "    else:\n",
    "        all_vectors_train.append(vec)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a2a111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors_train=np.hstack(np.array(all_vectors_train, dtype=\"object\")).reshape((len(all_vectors_train),100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c73fa2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145907, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vectors_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e9ac2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145907, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average train vector for Glove model.\n",
    "all_vectors_train_glove = []\n",
    "for i in range(0,len(X_train)):\n",
    "    vec =  get_mean_vector1(X_train[i],model_glove)\n",
    "    if numpy.isnan(vec).all():\n",
    "        all_vectors_train_glove.append(avg)\n",
    "    else:\n",
    "        all_vectors_train_glove.append(vec)\n",
    "    i+=1\n",
    "    \n",
    "all_vectors_train_glove=np.hstack(np.array(all_vectors_train_glove,dtype=\"object\")).reshape(len(all_vectors_train_glove),100)\n",
    "all_vectors_train_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3111c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors_train_glove=np.hstack(np.array(all_vectors_train_glove, dtype=\"object\")).reshape(len(all_vectors_train_glove),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b751f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average test vector for stemming model.\n",
    "all_vectors_test = []\n",
    "for i in range(0,len(X_test)):\n",
    "    vec = get_mean_vector(X_test[i],model)\n",
    "    if numpy.isnan(vec).all():\n",
    "        all_vectors_test.append(avg)\n",
    "    else:\n",
    "        all_vectors_test.append(vec)\n",
    "    i+=1\n",
    "    \n",
    "# Average test vector for Glove model.Here I use unstemming dataset.\n",
    "all_vectors_test_glove = []\n",
    "for i in range(0,len(X_test)):\n",
    "    vec =  get_mean_vector1(X_test[i],model_glove)\n",
    "    if numpy.isnan(vec).all():\n",
    "        all_vectors_test_glove.append(avg)\n",
    "    else:\n",
    "        all_vectors_test_glove.append(vec)\n",
    "    i+=1\n",
    "    \n",
    "# reshape the vectors for logistic model\n",
    "all_vectors_test=np.hstack(np.array(all_vectors_test, dtype=\"object\")).reshape((len(all_vectors_test),100))\n",
    "all_vectors_test_glove=np.hstack(np.array(all_vectors_test_glove, dtype=\"object\")).reshape(len(all_vectors_test_glove),100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2123ce",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "122a4347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.3min remaining:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "cv= LogisticRegressionCV(cv=5,scoring='accuracy',random_state=42,n_jobs=-1,verbose=3,max_iter=1000).fit(all_vectors_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef2bc8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.0min remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "cv1= LogisticRegressionCV(cv=5,scoring='accuracy',random_state=42,n_jobs=-1,verbose=3,max_iter=1000).fit(all_vectors_train_glove, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d82835fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 0.8158484514108302\n",
      "Testing Accuracy : 0.8150889601666804\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy :\", cv.score(all_vectors_train, y_train))\n",
    "print(\"Testing Accuracy :\", cv.score(all_vectors_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b2c0785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 0.7802161650914624\n",
      "Testing Accuracy : 0.7808207911834855\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy :\", cv1.score(all_vectors_train_glove, y_train))\n",
    "print(\"Testing Accuracy :\", cv1.score(all_vectors_test_glove, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9a1eff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for word2vec model is 0.810579812895571.\n",
      "The AUC for Glove model is 0.740645583399823.\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = cv.predict_proba(all_vectors_test)\n",
    "y_pred = cv.predict(all_vectors_test)\n",
    "\n",
    "y_pred_proba1 = cv1.predict_proba(all_vectors_test_glove)\n",
    "y_pred1 = cv1.predict(all_vectors_test_glove)\n",
    "\n",
    "auc_val = metrics.roc_auc_score(y_test, y_pred_proba,multi_class='ovo')\n",
    "auc_val1 = metrics.roc_auc_score(y_test, y_pred_proba1,multi_class='ovo')\n",
    "\n",
    "print(f\"\"\"The AUC for word2vec model is {auc_val}.\"\"\")\n",
    "print(f\"\"\"The AUC for Glove model is {auc_val1}.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "778f63f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MicroF1 for word2vec model is 0.8150889601666805.\n",
      "The MacroF1 for word2vec model is 0.527113591669395.\n"
     ]
    }
   ],
   "source": [
    "MicroF1_word2vec=f1_score(y_test, y_pred, average='micro')\n",
    "MacroF1_word2vec=f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"\"\"The MicroF1 for word2vec model is {MicroF1_word2vec}.\"\"\")\n",
    "print(f\"\"\"The MacroF1 for word2vec model is {MacroF1_word2vec}.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a73a603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MicroF1 for Glove model is 0.7808207911834855.\n",
      "The MacroF1 for Glove model is 0.4214751867154936.\n"
     ]
    }
   ],
   "source": [
    "MicroF1_Glove=f1_score(y_test, y_pred1, average='micro')\n",
    "MacroF1_Glove=f1_score(y_test, y_pred1, average='macro')\n",
    "\n",
    "print(f\"\"\"The MicroF1 for Glove model is {MicroF1_Glove}.\"\"\")\n",
    "print(f\"\"\"The MacroF1 for Glove model is {MacroF1_Glove}.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2633ab50",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2546f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=8, max_leaf_nodes=25, min_samples_leaf=25,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth = 8, random_state=42, max_leaf_nodes = 25, min_samples_leaf=25)\n",
    "clf.fit(all_vectors_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9047f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 0.7724303837375863\n",
      "Testing Accuracy : 0.7725964306275187\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy :\", clf.score(all_vectors_train, y_train))\n",
    "print(\"Testing Accuracy :\", clf.score(all_vectors_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b4b5546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=8, max_leaf_nodes=25, min_samples_leaf=25,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(max_depth = 8, random_state=42, max_leaf_nodes = 25, min_samples_leaf=25)\n",
    "clf1.fit(all_vectors_train_glove, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64390a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for word2vec vectors using Random Forest Model is 0.7313125104128649.\n",
      "The MicroF1 for word2vec vector using Random Forest Model is 0.7725964306275187.\n",
      "The MacroF1 for word2vec vector using Random Forest Model is 0.3352105110204975.\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba_rf = clf.predict_proba(all_vectors_test)\n",
    "y_pred_rf = clf.predict(all_vectors_test)\n",
    "\n",
    "auc_val = metrics.roc_auc_score(y_test, y_pred_proba_rf,multi_class='ovo')\n",
    "MicroF1_W_RF=f1_score(y_test, y_pred_rf, average='micro')\n",
    "MacroF1_W_RF=f1_score(y_test, y_pred_rf, average='macro')\n",
    "\n",
    "print(f\"\"\"The AUC for word2vec vectors using Random Forest Model is {auc_val}.\"\"\")\n",
    "print(f\"\"\"The MicroF1 for word2vec vector using Random Forest Model is {MicroF1_W_RF}.\"\"\")\n",
    "print(f\"\"\"The MacroF1 for word2vec vector using Random Forest Model is {MacroF1_W_RF}.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42ee14c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 0.7639797953490922\n",
      "Testing Accuracy : 0.7634399758752091\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy :\", clf1.score(all_vectors_train_glove, y_train))\n",
    "print(\"Testing Accuracy :\", clf1.score(all_vectors_test_glove, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9fefb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for Glove vectors using Random Forest Model is 0.6646588099260203.\n",
      "The MicroF1 for Glove vector using Random Forest Model is 0.763439975875209.\n",
      "The MacroF1 for Glove vector using Random Forest Model is 0.28861769659282294.\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba1_rf = clf1.predict_proba(all_vectors_test_glove)\n",
    "y_pred1_rf = clf1.predict(all_vectors_test_glove)\n",
    "\n",
    "auc_val_rf_g = metrics.roc_auc_score(y_test, y_pred_proba1_rf,multi_class='ovo')\n",
    "MicroF1_G_RF=f1_score(y_test, y_pred1_rf, average='micro')\n",
    "MacroF1_G_RF=f1_score(y_test, y_pred1_rf, average='macro')\n",
    "\n",
    "print(f\"\"\"The AUC for Glove vectors using Random Forest Model is {auc_val_rf_g}.\"\"\")\n",
    "print(f\"\"\"The MicroF1 for Glove vector using Random Forest Model is {MicroF1_G_RF}.\"\"\")\n",
    "print(f\"\"\"The MacroF1 for Glove vector using Random Forest Model is {MacroF1_G_RF}.\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
